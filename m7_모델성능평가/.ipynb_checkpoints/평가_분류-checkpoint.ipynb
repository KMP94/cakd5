{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "770f33bd",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#분류평가\" data-toc-modified-id=\"분류평가-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>분류평가</a></span><ul class=\"toc-item\"><li><span><a href=\"#Confusion-Matris(혼돈행렬,-오차행렬)\" data-toc-modified-id=\"Confusion-Matris(혼돈행렬,-오차행렬)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Confusion Matris(혼돈행렬, 오차행렬)</a></span></li><li><span><a href=\"#평가-지표\" data-toc-modified-id=\"평가-지표-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>평가 지표</a></span></li><li><span><a href=\"#정밀도-및-재현율-활용-시-유의사항\" data-toc-modified-id=\"정밀도-및-재현율-활용-시-유의사항-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>정밀도 및 재현율 활용 시 유의사항</a></span></li><li><span><a href=\"#Precision/Recall-Trade-off\" data-toc-modified-id=\"Precision/Recall-Trade-off-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Precision/Recall Trade-off</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6947c32",
   "metadata": {},
   "source": [
    "# 분류평가\n",
    "- 정확도만으로 불균형한 레이블 데이터 세트에서 평가지표로 사용하기에는 부적합\n",
    "- 정확도가 가지는 분류 평가 지표로의 한계점을 극복하기 위해 여러가지 분류 지표와 함께 적용해야 함\n",
    "\n",
    "## Confusion Matris(혼돈행렬, 오차행렬)\n",
    "- 이진분류에서 성능 지표로 잘 활용되는 오차행렬은 학습된 분류 모델이 예측을 수행하면 얼마나 혼동될 수 있는지도 함께 보여주는 지표\n",
    "- 이진 빈류의 예측 오류가 얼마인지와 더불어 어떠한 유형의 예측 오류가 발생하고 있는지를 함께 보여줌\n",
    "\n",
    "## 평가 지표\n",
    "- TP, FP, FN, TN는 예측클래스와 실제 클래스의 Positive 결정 값과 Negative 결정 값의 결함에 따라 결정\n",
    "- 앞문자 True/False는 예측값과 실제값이 같은가/틀린가를 의미하고 뒤 문자 N/P는 예측 결과값이 부정/긍정을 의미\n",
    "- 정확도 = (TP+TN)/(TP + TN + FP + FN)\n",
    "- 정밀도 = TP/(TP + FP) : P로 예측한 것 중에서 실제도 P\n",
    "- 재현율 = TP/(TP + FN) : 실제 P인 것 중에서 예측도 P\n",
    "- F1 = 2 * (정밀도 * 재현율) / (정밀도 + 재현율) : 정밀도와 재현율이 어느 한쪽으로 치우지지 않는 수치를 나타낼때 높아짐\n",
    "- 정밀도와 재현율은 Positive 데이터 세트의 예측 성능에 좀 더 초점에 맞춘 평가 지표\n",
    "- 재현율이 중요 지표인 경우 : 양성 데이터를 음성으로 잘못 판단하여 업무상 큰 영향이 발생하는 경우(암진단, 보험사기)\n",
    "- 정밀도가 더 중요한 지표인 사례 : 스팸 메일 여부 판단하는 경우로 스팸메일이 아닌데 스팸 매일로 분류해서 업무 차질발생\n",
    "\n",
    "## 정밀도 및 재현율 활용 시 유의사항\n",
    "- 정밀도와 재현율 성능 수치는 어느 한쪽만 참조하면 극단적인 수치 조작이 가능\n",
    "- 정밀도 100%가 되는 방법 : 확실한 기준이 되는 경우만 P로 예측하고 나머지는 모두 N로 예측 TP/(TP + FP) = 1\n",
    "- 재현율이 100%가 되는 방법 : 실제 양성 1000명중 30명 TP/(TP+FN) = 30/(30+0)=1\n",
    "- 분류가 정밀도, 재현율 중 하나에 상대적인 중요도를 부여할 수 있지만 하나만 강조해서는 안됨\n",
    "- 암 예측 모델에서 재현율을 높인다고 주로 양성만 판정한다면 환자의 불만과 불평이 커지게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2f71409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test,pred):\n",
    "    confusion = confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred)\n",
    "    recall= recall_score(y_test,pred)\n",
    "    print(f'오차행렬:\\n {confusion} ')\n",
    "    print(f'정확도: {round(accuracy,4)}, 정밀도: {round(precision,4)}, 재현율: {round(recall,4)} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95a92eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "def fillnas(df):\n",
    "    def callname(x):\n",
    "        m = re.compile('[A-Za-z]+[.]')\n",
    "        p = re.findall(m,x)\n",
    "        return p[0]\n",
    "    \n",
    "    df['Callname']=df.Name.apply(lambda x:callname(x))\n",
    "    \n",
    "    df1 = df.loc[df.Age.isnull()]\n",
    "    age_nulllist = list(set(df1.Callname.values.tolist()))\n",
    "    \n",
    "    df2 = df.loc[df.Age.notnull()]\n",
    "    pivot = pd.pivot_table(df2, index = 'Callname', values = 'Age',aggfunc = 'mean')\n",
    "    \n",
    "    for age in age_nulllist:\n",
    "        df.loc[(df.Age.isnull())&(df.Callname == age),['Age']]=(pivot.loc[age][0])\n",
    "        \n",
    "    df['Embarked'].fillna(method = 'ffill',inplace=True)\n",
    "    \n",
    "    df3 = df.loc[df.Cabin.notnull()]\n",
    "\n",
    "    df3['Cabins'] = df3['Cabin'].str[:1]\n",
    "    df4 = df.loc[df.Cabin.isnull()]\n",
    "    \n",
    "    for i in range(1,4):\n",
    "        df33 = df3.loc[df3.Pclass == i]\n",
    "        cabin_fill_list=list(set(df33.Cabins.values.tolist()))\n",
    "        df44 = df4.loc[df4.Pclass == i]\n",
    "        fill_index = list(df44.index)\n",
    "        for index in fill_index:\n",
    "            df.loc[index,'Cabin'] = np.random.choice(cabin_fill_list)\n",
    "            \n",
    "    return df\n",
    "\n",
    "# 불필요 항목 제거\n",
    "def drop_feat(df):\n",
    "    df.drop(['PassengerId','Name','Ticket','Callname'],axis=1,inplace = True)\n",
    "    return df\n",
    "\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df[['Fare']])\n",
    "    fare_scaled = scaler.transform(df[['Fare']])\n",
    "    df['Fare'] = fare_scaled\n",
    "    \n",
    "    return df\n",
    "\n",
    "def transform_features(df):\n",
    "    df = fillnas(df)\n",
    "    df = drop_feat(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "991e6c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "t_df = pd.read_csv('./dataset/train.csv')\n",
    "y_t_df = t_df['Survived']\n",
    "X_t_df = t_df.drop('Survived',axis=1)\n",
    "X_t_df = transform_features(X_t_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "09da2e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[107  11]\n",
      " [ 14  47]] \n",
      "정확도: 0.8603, 정밀도: 0.8103, 재현율: 0.7705 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_t_df,y_t_df,test_size=0.2, random_state=11) \n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test,pred)\n",
    "#사망한 사람\n",
    "#살았다고 분류했는데 죽은사람\n",
    "#죽었다고 분류했다는 생존한 사람\n",
    "#셍존한 사람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7e5644c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy : 0.8603351955307262\n",
      "precision : 0.8103448275862069\n",
      "recall : 0.7704918032786885\n",
      "F1 score : 0.7899159663865546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TN = 107\n",
    "FP=11\n",
    "FN=14\n",
    "TP=47\n",
    "precision = TP/(TP + FP)\n",
    "recall = TP/(TP + FN)\n",
    "print(f'''\n",
    "accuracy : {(TP+TN)/(TP + TN + FP + FN)}\n",
    "precision : {TP/(TP + FP)}\n",
    "recall : {TP/(TP + FN)}\n",
    "F1 score : {2*(precision*recall)/(precision+recall)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84890c13",
   "metadata": {},
   "source": [
    "## Precision/Recall Trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f19014f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58468012, 0.41531988, 0.        ],\n",
       "       [0.87010543, 0.12989457, 0.        ],\n",
       "       [0.89757002, 0.10242998, 0.        ],\n",
       "       [0.84317155, 0.15682845, 0.        ],\n",
       "       [0.83575991, 0.16424009, 0.        ],\n",
       "       [0.85314304, 0.14685696, 0.        ],\n",
       "       [0.91444308, 0.08555692, 0.        ],\n",
       "       [0.18855067, 0.81144933, 1.        ],\n",
       "       [0.77549275, 0.22450725, 0.        ],\n",
       "       [0.31711505, 0.68288495, 1.        ],\n",
       "       [0.90207696, 0.09792304, 0.        ],\n",
       "       [0.8801919 , 0.1198081 , 0.        ],\n",
       "       [0.88464355, 0.11535645, 0.        ],\n",
       "       [0.89109879, 0.10890121, 0.        ],\n",
       "       [0.55897079, 0.44102921, 0.        ],\n",
       "       [0.86415128, 0.13584872, 0.        ],\n",
       "       [0.91087749, 0.08912251, 0.        ],\n",
       "       [0.72231176, 0.27768824, 0.        ],\n",
       "       [0.67867388, 0.32132612, 0.        ],\n",
       "       [0.16191821, 0.83808179, 1.        ],\n",
       "       [0.6905475 , 0.3094525 , 0.        ],\n",
       "       [0.64804034, 0.35195966, 0.        ],\n",
       "       [0.8427494 , 0.1572506 , 0.        ],\n",
       "       [0.78922452, 0.21077548, 0.        ],\n",
       "       [0.90299364, 0.09700636, 0.        ],\n",
       "       [0.72557572, 0.27442428, 0.        ],\n",
       "       [0.842684  , 0.157316  , 0.        ],\n",
       "       [0.94185641, 0.05814359, 0.        ],\n",
       "       [0.67880012, 0.32119988, 0.        ],\n",
       "       [0.64458109, 0.35541891, 0.        ],\n",
       "       [0.09280403, 0.90719597, 1.        ],\n",
       "       [0.20698499, 0.79301501, 1.        ],\n",
       "       [0.88699325, 0.11300675, 0.        ],\n",
       "       [0.1877462 , 0.8122538 , 1.        ],\n",
       "       [0.63599058, 0.36400942, 0.        ],\n",
       "       [0.7753669 , 0.2246331 , 0.        ],\n",
       "       [0.93150036, 0.06849964, 0.        ],\n",
       "       [0.44818846, 0.55181154, 1.        ],\n",
       "       [0.9579467 , 0.0420533 , 0.        ],\n",
       "       [0.91333325, 0.08666675, 0.        ],\n",
       "       [0.61859257, 0.38140743, 0.        ],\n",
       "       [0.92757157, 0.07242843, 0.        ],\n",
       "       [0.16728348, 0.83271652, 1.        ],\n",
       "       [0.29243674, 0.70756326, 1.        ],\n",
       "       [0.33884708, 0.66115292, 1.        ],\n",
       "       [0.33882877, 0.66117123, 1.        ],\n",
       "       [0.11417007, 0.88582993, 1.        ],\n",
       "       [0.61754244, 0.38245756, 0.        ],\n",
       "       [0.04725447, 0.95274553, 1.        ],\n",
       "       [0.90295808, 0.09704192, 0.        ],\n",
       "       [0.58299778, 0.41700222, 0.        ],\n",
       "       [0.91440072, 0.08559928, 0.        ],\n",
       "       [0.87265746, 0.12734254, 0.        ],\n",
       "       [0.24727629, 0.75272371, 1.        ],\n",
       "       [0.64553081, 0.35446919, 0.        ],\n",
       "       [0.77604298, 0.22395702, 0.        ],\n",
       "       [0.73752753, 0.26247247, 0.        ],\n",
       "       [0.87033484, 0.12966516, 0.        ],\n",
       "       [0.83268634, 0.16731366, 0.        ],\n",
       "       [0.52152577, 0.47847423, 0.        ],\n",
       "       [0.6791688 , 0.3208312 , 0.        ],\n",
       "       [0.90497811, 0.09502189, 0.        ],\n",
       "       [0.52075329, 0.47924671, 0.        ],\n",
       "       [0.4550289 , 0.5449711 , 1.        ],\n",
       "       [0.69611004, 0.30388996, 0.        ],\n",
       "       [0.9217602 , 0.0782398 , 0.        ],\n",
       "       [0.3255439 , 0.6744561 , 1.        ],\n",
       "       [0.40270719, 0.59729281, 1.        ],\n",
       "       [0.04552462, 0.95447538, 1.        ],\n",
       "       [0.84631419, 0.15368581, 0.        ],\n",
       "       [0.86097109, 0.13902891, 0.        ],\n",
       "       [0.83553599, 0.16446401, 0.        ],\n",
       "       [0.91333102, 0.08666898, 0.        ],\n",
       "       [0.06930894, 0.93069106, 1.        ],\n",
       "       [0.77415108, 0.22584892, 0.        ],\n",
       "       [0.89109879, 0.10890121, 0.        ],\n",
       "       [0.6060991 , 0.3939009 , 0.        ],\n",
       "       [0.76877814, 0.23122186, 0.        ],\n",
       "       [0.16300342, 0.83699658, 1.        ],\n",
       "       [0.88464902, 0.11535098, 0.        ],\n",
       "       [0.19482013, 0.80517987, 1.        ],\n",
       "       [0.38491953, 0.61508047, 1.        ],\n",
       "       [0.03890562, 0.96109438, 1.        ],\n",
       "       [0.86661594, 0.13338406, 0.        ],\n",
       "       [0.04972939, 0.95027061, 1.        ],\n",
       "       [0.07407086, 0.92592914, 1.        ],\n",
       "       [0.86160131, 0.13839869, 0.        ],\n",
       "       [0.87123344, 0.12876656, 0.        ],\n",
       "       [0.11575999, 0.88424001, 1.        ],\n",
       "       [0.90337525, 0.09662475, 0.        ],\n",
       "       [0.89109879, 0.10890121, 0.        ],\n",
       "       [0.75130398, 0.24869602, 0.        ],\n",
       "       [0.72867564, 0.27132436, 0.        ],\n",
       "       [0.91440072, 0.08559928, 0.        ],\n",
       "       [0.30963914, 0.69036086, 1.        ],\n",
       "       [0.93042419, 0.06957581, 0.        ],\n",
       "       [0.0715664 , 0.9284336 , 1.        ],\n",
       "       [0.91623725, 0.08376275, 0.        ],\n",
       "       [0.64953623, 0.35046377, 0.        ],\n",
       "       [0.04913992, 0.95086008, 1.        ],\n",
       "       [0.4839015 , 0.5160985 , 1.        ],\n",
       "       [0.91812086, 0.08187914, 0.        ],\n",
       "       [0.07754401, 0.92245599, 1.        ],\n",
       "       [0.90863379, 0.09136621, 0.        ],\n",
       "       [0.46255086, 0.53744914, 1.        ],\n",
       "       [0.89089582, 0.10910418, 0.        ],\n",
       "       [0.86409799, 0.13590201, 0.        ],\n",
       "       [0.87788593, 0.12211407, 0.        ],\n",
       "       [0.57047719, 0.42952281, 0.        ],\n",
       "       [0.78460661, 0.21539339, 0.        ],\n",
       "       [0.8843378 , 0.1156622 , 0.        ],\n",
       "       [0.89713646, 0.10286354, 0.        ],\n",
       "       [0.54599813, 0.45400187, 0.        ],\n",
       "       [0.36584089, 0.63415911, 1.        ],\n",
       "       [0.89067457, 0.10932543, 0.        ],\n",
       "       [0.94218907, 0.05781093, 0.        ],\n",
       "       [0.84473088, 0.15526912, 0.        ],\n",
       "       [0.75031694, 0.24968306, 0.        ],\n",
       "       [0.10491113, 0.89508887, 1.        ],\n",
       "       [0.93737824, 0.06262176, 0.        ],\n",
       "       [0.91440888, 0.08559112, 0.        ],\n",
       "       [0.86874391, 0.13125609, 0.        ],\n",
       "       [0.92704808, 0.07295192, 0.        ],\n",
       "       [0.72738182, 0.27261818, 0.        ],\n",
       "       [0.99069133, 0.00930867, 0.        ],\n",
       "       [0.91440888, 0.08559112, 0.        ],\n",
       "       [0.87200982, 0.12799018, 0.        ],\n",
       "       [0.66742296, 0.33257704, 0.        ],\n",
       "       [0.36713197, 0.63286803, 1.        ],\n",
       "       [0.80018609, 0.19981391, 0.        ],\n",
       "       [0.04913992, 0.95086008, 1.        ],\n",
       "       [0.47932377, 0.52067623, 1.        ],\n",
       "       [0.29609549, 0.70390451, 1.        ],\n",
       "       [0.50678474, 0.49321526, 0.        ],\n",
       "       [0.42731809, 0.57268191, 1.        ],\n",
       "       [0.65694241, 0.34305759, 0.        ],\n",
       "       [0.20419507, 0.79580493, 1.        ],\n",
       "       [0.87528957, 0.12471043, 0.        ],\n",
       "       [0.90215464, 0.09784536, 0.        ],\n",
       "       [0.14723091, 0.85276909, 1.        ],\n",
       "       [0.10897566, 0.89102434, 1.        ],\n",
       "       [0.8628626 , 0.1371374 , 0.        ],\n",
       "       [0.87935269, 0.12064731, 0.        ],\n",
       "       [0.90981748, 0.09018252, 0.        ],\n",
       "       [0.91457304, 0.08542696, 0.        ],\n",
       "       [0.32220422, 0.67779578, 1.        ],\n",
       "       [0.9213395 , 0.0786605 , 0.        ],\n",
       "       [0.74992229, 0.25007771, 0.        ],\n",
       "       [0.12426844, 0.87573156, 1.        ],\n",
       "       [0.78771754, 0.21228246, 0.        ],\n",
       "       [0.45936962, 0.54063038, 1.        ],\n",
       "       [0.37151898, 0.62848102, 1.        ],\n",
       "       [0.41945835, 0.58054165, 1.        ],\n",
       "       [0.89762444, 0.10237556, 0.        ],\n",
       "       [0.18107568, 0.81892432, 1.        ],\n",
       "       [0.1395743 , 0.8604257 , 1.        ],\n",
       "       [0.55620187, 0.44379813, 0.        ],\n",
       "       [0.85689244, 0.14310756, 0.        ],\n",
       "       [0.27140294, 0.72859706, 1.        ],\n",
       "       [0.31143952, 0.68856048, 1.        ],\n",
       "       [0.85504861, 0.14495139, 0.        ],\n",
       "       [0.15984416, 0.84015584, 1.        ],\n",
       "       [0.92478122, 0.07521878, 0.        ],\n",
       "       [0.3256219 , 0.6743781 , 1.        ],\n",
       "       [0.61354624, 0.38645376, 0.        ],\n",
       "       [0.37251513, 0.62748487, 1.        ],\n",
       "       [0.1361432 , 0.8638568 , 1.        ],\n",
       "       [0.63545172, 0.36454828, 0.        ],\n",
       "       [0.9145519 , 0.0854481 , 0.        ],\n",
       "       [0.08885007, 0.91114993, 1.        ],\n",
       "       [0.90342249, 0.09657751, 0.        ],\n",
       "       [0.12984458, 0.87015542, 1.        ],\n",
       "       [0.70210875, 0.29789125, 0.        ],\n",
       "       [0.72458116, 0.27541884, 0.        ],\n",
       "       [0.57265564, 0.42734436, 0.        ],\n",
       "       [0.93605788, 0.06394212, 0.        ],\n",
       "       [0.84766397, 0.15233603, 0.        ],\n",
       "       [0.52142025, 0.47857975, 0.        ],\n",
       "       [0.44944511, 0.55055489, 1.        ]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred_proba  # 0과 1이 될 확률\n",
    "pred=lr_clf.predict(X_test)\n",
    "pred_proba_result = np.concatenate([pred_proba,pred.reshape(-1,1)],axis=1)\n",
    "pred_proba_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0e1c6ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "X=[[1,-1,2],\n",
    "  [2,0,0],\n",
    "  [0,1.1,1.2]]\n",
    "binarizer = Binarizer(threshold=1.1)\n",
    "binarizer.fit_transform(X)\n",
    "# 임계치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "28e2c222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[107  11]\n",
      " [ 14  47]] \n",
      "정확도: 0.8603, 정밀도: 0.8103, 재현율: 0.7705 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "custom_treshold = 0.5\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold=custom_treshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "# pred_proba_1\n",
    "get_clf_eval(y_test,custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6c4c9f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[114   4]\n",
      " [ 17  44]] \n",
      "정확도: 0.8827, 정밀도: 0.9167, 재현율: 0.7213 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 분류 결정 임계값을 0.5 -> 0.4\n",
    "custom_treshold = 0.4\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold=custom_treshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "# pred_proba_1\n",
    "get_clf_eval(y_test,custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6db45239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 treshold 값: 0.35\n",
      "오차행렬:\n",
      " [[93 25]\n",
      " [ 7 54]] \n",
      "정확도: 0.8212, 정밀도: 0.6835, 재현율: 0.8852 \n",
      "\n",
      "현재 treshold 값: 0.4\n",
      "오차행렬:\n",
      " [[99 19]\n",
      " [11 50]] \n",
      "정확도: 0.8324, 정밀도: 0.7246, 재현율: 0.8197 \n",
      "\n",
      "현재 treshold 값: 0.45\n",
      "오차행렬:\n",
      " [[104  14]\n",
      " [ 12  49]] \n",
      "정확도: 0.8547, 정밀도: 0.7778, 재현율: 0.8033 \n",
      "\n",
      "현재 treshold 값: 0.5\n",
      "오차행렬:\n",
      " [[107  11]\n",
      " [ 14  47]] \n",
      "정확도: 0.8603, 정밀도: 0.8103, 재현율: 0.7705 \n",
      "\n",
      "현재 treshold 값: 0.52\n",
      "오차행렬:\n",
      " [[108  10]\n",
      " [ 14  47]] \n",
      "정확도: 0.8659, 정밀도: 0.8246, 재현율: 0.7705 \n",
      "\n",
      "현재 treshold 값: 0.55\n",
      "오차행렬:\n",
      " [[111   7]\n",
      " [ 15  46]] \n",
      "정확도: 0.8771, 정밀도: 0.8679, 재현율: 0.7541 \n",
      "\n",
      "현재 treshold 값: 0.57\n",
      "오차행렬:\n",
      " [[112   6]\n",
      " [ 16  45]] \n",
      "정확도: 0.8771, 정밀도: 0.8824, 재현율: 0.7377 \n",
      "\n",
      "현재 treshold 값: 0.6\n",
      "오차행렬:\n",
      " [[114   4]\n",
      " [ 17  44]] \n",
      "정확도: 0.8827, 정밀도: 0.9167, 재현율: 0.7213 \n",
      "\n",
      "현재 treshold 값: 0.65\n",
      "오차행렬:\n",
      " [[115   3]\n",
      " [ 21  40]] \n",
      "정확도: 0.8659, 정밀도: 0.9302, 재현율: 0.6557 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "custom_treshold = [0.35,0.4,0.45,0.5,0.52,0.55,0.57,0.60,0.65]\n",
    "\n",
    "for treshold in custom_treshold:\n",
    "    pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "    binarizer = Binarizer(threshold=treshold).fit(pred_proba_1)\n",
    "    custom_predict = binarizer.transform(pred_proba_1)\n",
    "    print(f'현재 treshold 값: {treshold}')\n",
    "    get_clf_eval(y_test,custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff05be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[과제] 임계값을 0~1사이로 변경시킬때 정밀도와 재현율의 변화 추세를 시각화하여 나타내시오"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
